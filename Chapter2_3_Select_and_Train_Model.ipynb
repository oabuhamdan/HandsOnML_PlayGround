{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "% store -r housing_prepared\n",
    "% store -r housing_labels\n",
    "% store -r housing_data_pd\n",
    "housing_labels = housing_labels\n",
    "housing_data_pd = housing_data_pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "\n",
    "class CombinedAttributeAdder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms__per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms__per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('attribs_adder', CombinedAttributeAdder()),\n",
    "    ('srd_scalar', StandardScaler())\n",
    "])\n",
    "housing_num = housing_data_pd.drop('ocean_proximity', axis=1)\n",
    "num_attr = list(housing_num)  # list(pandas DF) will create a list of the header names\n",
    "cat_attr = ['ocean_proximity']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    # name, transformer, list of columns names or indexes\n",
    "    ('num', numeric_pipeline, num_attr),\n",
    "    ('cat', OneHotEncoder(), cat_attr)\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing_data_pd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting with a liner regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "l_reg = LinearRegression()\n",
    "l_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85657.90192014 305492.60737488 152056.46122456 186095.70946094\n",
      " 244550.67966089]\n",
      "[72100.0, 279600.0, 82700.0, 112500.0, 238300.0]\n"
     ]
    }
   ],
   "source": [
    "# try on training set\n",
    "some_data = housing_data_pd.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(l_reg.predict(some_data_prepared))\n",
    "print(list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# check the RMSE for the whole training set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = l_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "68627.87390018745"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Notice that the RMSE value is 68k, which is too  much.\n",
    "#### To fix this we can:\n",
    "- Select another model\n",
    "- Choose better features\n",
    "- reduce the constraints"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor()"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DecisionTreeRegressor Model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(tree_rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Another way to evaluate the model is to:\n",
    "- Use train_test_split function to split the training set into a smaller training and validation set.\n",
    "- Then train using the training and evaluate using the validation set.\n",
    "#### We will use K-Fold cross validation feature. It will split the data into K folds, 1 for evaluation and the others for training..\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [73388.89081265 69526.11285471 68138.26875887 71055.70049379\n",
      " 67970.894958   78134.04341471 71082.24273858 72822.61578241\n",
      " 68580.25237388 72878.3665384 ]\n",
      "Mean: 71357.73887259862\n",
      "STD: 2959.2932306058656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross_val_score expects a utility function (greater is better) rather than a cost function (smaller is better). So, the scoring function is the opposite of MSE.\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "\n",
    "def display_scores(scorez):\n",
    "    print(f\"Scores: {scorez}\")\n",
    "    print(f\"Mean: {scorez.mean()}\")\n",
    "    print(f\"STD: {scorez.std()}\")\n",
    "\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [71762.76364394 64114.99166359 67771.17124356 68635.19072082\n",
      " 66846.14089488 72528.03725385 73997.08050233 68802.33629334\n",
      " 66443.28836884 70139.79923956]\n",
      "Mean: 69104.07998247063\n",
      "STD: 2880.3282098180644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cross_val_score expects a utility function (greater is better) rather than a cost function (smaller is better). So, the scoring function is the opposite of MSE.\n",
    "scores = cross_val_score(l_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "l_reg_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "display_scores(l_reg_rmse_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [51310.81233402 49097.88334955 47020.82288695 51999.92045315\n",
      " 47256.03916104 51551.74120999 52270.36551712 49808.97674182\n",
      " 48481.92924755 53875.59320091]\n",
      "Mean: 50267.40841020938\n",
      "STD: 2171.2941242678603\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random forest works by training many decision tress with random set of features and average these predictions\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(housing_prepared, housing_labels)\n",
    "scores = cross_val_score(rfr, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rfr_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "display_scores(rfr_rmse_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save your model, hyperparams, trained params, cross-validation score and maybe the predictions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rfr, \"random_forest_regressor.pkl\")  # to save\n",
    "rfr_loaded = joblib.load(\"random_forest_regressor.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Fine-Tuning\n",
    "Fine-tuning is done by trying different combination of hyperparams.\n",
    "The trial of different combinations of hyperparams can be done using \"GridSearchCV\". It will do cross-validation to evaluate the combinations.\n",
    "You define the combinations to try and it will try it by n number of folds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n             param_grid=[{'max_features': [2, 4, 6, 8],\n                          'n_estimators': [3, 10, 30]},\n                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n                          'n_estimators': [3, 10]}],\n             return_train_score=True, scoring='neg_mean_squared_error')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap':[False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "# 3 * 4 from the first dict +\n",
    "# 2 * 3 from the second dict *\n",
    "# 5 folds (cv = 5) = 90\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 8, 'n_estimators': 30}\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor(max_features=8, n_estimators=30)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "grid_search.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since 8 and 30 are chosen (maximum from each side), we should try higher numbers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64015.32794586548 {'max_features': 2, 'n_estimators': 3}\n",
      "55385.81422939445 {'max_features': 2, 'n_estimators': 10}\n",
      "52765.00695744444 {'max_features': 2, 'n_estimators': 30}\n",
      "59989.17574933045 {'max_features': 4, 'n_estimators': 3}\n",
      "52469.71776755092 {'max_features': 4, 'n_estimators': 10}\n",
      "50459.4432569964 {'max_features': 4, 'n_estimators': 30}\n",
      "59852.09591934263 {'max_features': 6, 'n_estimators': 3}\n",
      "52141.87544436116 {'max_features': 6, 'n_estimators': 10}\n",
      "50194.02290930418 {'max_features': 6, 'n_estimators': 30}\n",
      "58729.79821140529 {'max_features': 8, 'n_estimators': 3}\n",
      "52529.83307246577 {'max_features': 8, 'n_estimators': 10}\n",
      "50184.93003465762 {'max_features': 8, 'n_estimators': 30}\n",
      "62801.90889315715 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "53698.268819461344 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "59625.651046185296 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "52472.341054040684 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "58557.785549932865 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51714.38288403705 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "curves = grid_search.cv_results_\n",
    "for mean_score, params in zip(curves[\"mean_test_score\"], curves[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compare the RMSE here after fine-tuning the model (50184 with {'max_features': 8, 'n_estimators': 30}) with the RMSE before without fine-tuning (50267)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some data preparation steps can be treated as hyperparams. Gird search will do this automatically by adding some combined features, handling outliers, features selections, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GridSearch is good when you have few number of hyperparams. If you have huge number of these params, RandomizedSearchCV is better to be used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.42658245e-02 6.10336731e-02 4.28724320e-02 1.46903759e-02\n",
      " 1.49597221e-02 1.46504244e-02 1.41665385e-02 3.72043355e-01\n",
      " 4.09704522e-02 1.12899974e-01 5.67994003e-02 3.37101753e-03\n",
      " 1.82703508e-01 9.46248953e-05 1.63451015e-03 2.84416839e-03]\n"
     ]
    }
   ],
   "source": [
    "# To check the importance of each feature:\n",
    "feature_importance = grid_search.best_estimator_.feature_importances_\n",
    "print(feature_importance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9k/6fb9wvz9449bq955d8fnxskm0000gn/T/ipykernel_4090/520699814.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# let's show the above scores with their names\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mextra_attribs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"rooms_per_hold\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"pop_per_hhold\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"bedrooms_per_room\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mcat_encoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfull_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_transformers_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"cat\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mcat_one_hot_attribs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcat_encoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcategories_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mattributes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnum_attr\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mextra_attribs\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mcat_one_hot_attribs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/9k/6fb9wvz9449bq955d8fnxskm0000gn/T/ipykernel_4090/520699814.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# let's show the above scores with their names\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mextra_attribs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"rooms_per_hold\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"pop_per_hhold\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"bedrooms_per_room\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mcat_encoder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfull_pipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_transformers_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"cat\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mcat_one_hot_attribs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcat_encoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcategories_\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mattributes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnum_attr\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mextra_attribs\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mcat_one_hot_attribs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_38_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    163\u001B[0m         \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    164\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m             \u001B[0mmain_debugger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    166\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1146\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1147\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1160\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1162\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1163\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# let's show the above scores with their names\n",
    "extra_attribs = [\"rooms_per_hold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attr + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importance, attributes), reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}